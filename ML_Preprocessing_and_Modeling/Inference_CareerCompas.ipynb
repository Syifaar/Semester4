{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFxDhyA_ziZZ",
        "outputId": "10e22a03-1007-49e4-c7c8-41057a30a56b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Collecting pymupdf\n",
            "  Downloading pymupdf-1.26.1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.72.1)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading pymupdf-1.26.1-cp39-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymupdf\n",
            "Successfully installed pymupdf-1.26.1\n"
          ]
        }
      ],
      "source": [
        "pip install pandas numpy tensorflow pymupdf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "import re\n",
        "\n",
        "# ✅ Download dulu data yang diperlukan\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hC2sAtcQ3qeF",
        "outputId": "efabf13e-0519-42d8-89ef-ed3a7bb9ec25"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz  # PyMuPDF\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import re\n",
        "import string\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# =============================\n",
        "# CONFIGURATION\n",
        "# =============================\n",
        "\n",
        "MAX_LEN = 200  # Sesuaikan dengan saat training\n",
        "TOP_N = 20      # Jumlah rekomendasi teratas\n",
        "\n",
        "# =============================\n",
        "# FUNGSI PREPROCESSING\n",
        "# =============================\n",
        "\n",
        "def preprocess_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\n|\\r|\\t', ' ', text)\n",
        "    text = re.sub(r'[^a-z\\s]', ' ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [w for w in tokens if w not in stop_words and len(w) > 1]\n",
        "    tokens = [lemmatizer.lemmatize(w) for w in tokens]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "# =============================\n",
        "# EKSTRAKSI TEKS DARI PDF\n",
        "# =============================\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    doc = fitz.open(pdf_path)\n",
        "    text = \"\"\n",
        "    for page in doc:\n",
        "        text += page.get_text()\n",
        "    doc.close()\n",
        "    return text\n",
        "\n",
        "# =============================\n",
        "# LOAD TOKENIZER & MODEL\n",
        "# =============================\n",
        "\n",
        "with open(\"/content/drive/MyDrive/Capstone - Career Compas/tokenizer.pkl\", \"rb\") as f:\n",
        "    tokenizer = pickle.load(f)\n",
        "\n",
        "model = tf.keras.models.load_model(\"/content/drive/MyDrive/Capstone - Career Compas/jobmatch_model.h5\")\n",
        "\n",
        "# =============================\n",
        "# LOAD DATA JOBS\n",
        "# =============================\n",
        "\n",
        "jobs_df = pd.read_csv(\"/content/drive/MyDrive/Capstone - Career Compas/jobdesc_clean.csv\")\n",
        "jobs_df['job_text'] = jobs_df['Job Description'].apply(preprocess_text)\n",
        "\n",
        "# =============================\n",
        "# PREDIKSI DAN REKOMENDASI\n",
        "# =============================\n",
        "\n",
        "def get_recommendations(resume_text, top_n=TOP_N):\n",
        "    resume_clean = preprocess_text(resume_text)\n",
        "\n",
        "    # Tokenisasi dan padding\n",
        "    resume_seq = tokenizer.texts_to_sequences([resume_clean])\n",
        "    resume_pad = pad_sequences(resume_seq, maxlen=MAX_LEN, padding=\"post\")\n",
        "\n",
        "    job_seqs = tokenizer.texts_to_sequences(jobs_df['job_text'])\n",
        "    job_pad = pad_sequences(job_seqs, maxlen=MAX_LEN, padding=\"post\")\n",
        "\n",
        "    # Duplikat resume sebanyak jumlah job\n",
        "    resume_batch = np.repeat(resume_pad, len(job_pad), axis=0)\n",
        "\n",
        "    # Prediksi kecocokan\n",
        "    predictions = model.predict([resume_batch, job_pad], verbose=0).flatten()\n",
        "\n",
        "    jobs_df[\"match_score\"] = predictions\n",
        "    top_jobs = jobs_df.sort_values(\"match_score\", ascending=False).head(top_n)\n",
        "\n",
        "    return top_jobs[['Job Title','skills', 'Company', 'match_score']]\n",
        "\n",
        "# =============================\n",
        "# MAIN\n",
        "# =============================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    pdf_path = \"/content/drive/MyDrive/Capstone - Career Compas/cv/cv1.pdf\"  # file resume PDF\n",
        "    resume_text = extract_text_from_pdf(pdf_path)\n",
        "\n",
        "    print(\"=== Isi CV (cv1.pdf) sebelum di preprocessing ===\\n\")\n",
        "    print(resume_text[:500])\n",
        "\n",
        "    recommendations = get_recommendations(resume_text)\n",
        "\n",
        "    print(\"\\n=== Top Job Recommendations ===\")\n",
        "    print(recommendations.to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xe0HGOCNzkDT",
        "outputId": "3c973f5e-297b-4771-f7f2-ee2877d12b07"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Isi CV (cv1.pdf) ===\n",
            "\n",
            "         HR ADMINISTRATOR/MARKETING ASSOCIATE \n",
            " \n",
            "HR ADMINISTRATOR       Summary     Dedicated Customer Service Manager with 15+ years of \n",
            "experience in Hospitality and Customer Service Management.   Respected builder and leader of \n",
            "customer-focused teams; strives to instill a shared, enthusiastic commitment to customer \n",
            "service.         Highlights         Focused on customer satisfaction  Team management  Marketing \n",
            "savvy  Conflict resolution techniques     Training and development  Skilled mult\n",
            "\n",
            "=== Top Job Recommendations ===\n",
            "                   Job Title                                                                                                               skills                                   Company  match_score\n",
            "     Human Resources Manager                                       HR policies and procedures Employee relations Recruitment Communication skills New Oriental Education & Technology Group     0.989276\n",
            "     Human Resources Manager                                       HR policies and procedures Employee relations Recruitment Communication skills                        Berkshire Hathaway     0.989276\n",
            "                  HR Manager                   Strategic HR planning Employee relations Talent management HR policy development Leadership skills                   ProSiebenSat.1 Media SE     0.989015\n",
            "                  HR Manager                   Strategic HR planning Employee relations Talent management HR policy development Leadership skills                          Waste Management     0.989015\n",
            "                  HR Manager                   Strategic HR planning Employee relations Talent management HR policy development Leadership skills                          Procter & Gamble     0.989015\n",
            "                  HR Manager                   Strategic HR planning Employee relations Talent management HR policy development Leadership skills                              State Street     0.989015\n",
            "Business Development Manager                                                          Sales management Sales strategy development Team leadership                             Newell Brands     0.985668\n",
            "Business Development Manager                                                          Sales management Sales strategy development Team leadership                          Brambles Limited     0.985668\n",
            "Business Development Manager                                                          Sales management Sales strategy development Team leadership                     Beacon Roofing Supply     0.985668\n",
            "Business Development Manager                                                          Sales management Sales strategy development Team leadership             Sun Pharmaceutical Industries     0.985668\n",
            "Business Development Manager                                                          Sales management Sales strategy development Team leadership               Berger Paints India Limited     0.985668\n",
            "Business Development Manager                                                          Sales management Sales strategy development Team leadership                         Boston Scientific     0.985668\n",
            "    Customer Service Manager Customer support Team leadership Customer satisfaction Issue resolution Performance metrics Training and development                Farmers Insurance Exchange     0.983023\n",
            "    Customer Service Manager Customer support Team leadership Customer satisfaction Issue resolution Performance metrics Training and development                   American Airlines Group     0.983023\n",
            "    Customer Service Manager Customer support Team leadership Customer satisfaction Issue resolution Performance metrics Training and development     Adani Ports and Special Economic Zone     0.983023\n",
            "    Customer Service Manager Customer support Team leadership Customer satisfaction Issue resolution Performance metrics Training and development                    Advanced Micro Devices     0.983023\n",
            "    Customer Service Manager Customer support Team leadership Customer satisfaction Issue resolution Performance metrics Training and development New Oriental Education & Technology Group     0.983023\n",
            "    Customer Service Manager Customer support Team leadership Customer satisfaction Issue resolution Performance metrics Training and development                             Compass Group     0.983023\n",
            "    Customer Service Manager Customer support Team leadership Customer satisfaction Issue resolution Performance metrics Training and development                     Deutsche Lufthansa AG     0.983023\n",
            "    Customer Service Manager Customer support Team leadership Customer satisfaction Issue resolution Performance metrics Training and development                                   Carvana     0.983023\n"
          ]
        }
      ]
    }
  ]
}